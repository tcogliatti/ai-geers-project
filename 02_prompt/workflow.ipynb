{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b50e32",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "Los workflows son tecnicas que permiten mas control del proceso disminuyendo los margenes para las alucinaciones y la variabilidad de respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5220e",
   "metadata": {},
   "source": [
    "## Disminucion de la variabilidad\n",
    "Para disminuir la variabilidad de respuestas sobre una misma historia clinica se van a ir almacenando los resumenes generados por la AI en una BBDD. \n",
    "Fujo para un paciente dado, verificar si existe un resumen en la tabla *ai_resumen_evolucion*:\n",
    "1. No existe resumen\n",
    "    * Obtener paciente y evoluciones de la BBDD\n",
    "    * Generar resumen\n",
    "    * Almacenar resumen en tabla *ai_resumen_evolucion*\n",
    "    * almacenar las referencias a las evoluciones usadas para ese resumen en *ai_referencia_evolucion*\n",
    "2. Existe resumen\n",
    "    * Si existe mas de uno, traer el ultimo resumen\n",
    "    * Obtener las evoluciones del paciente\n",
    "    * Obtener las referencias a las evoluciones usadas en el ultimo resumen de la tabla *ai_referencia_evolucion*\n",
    "    * Verificar si las evoluciones actuales son las mismas que las usadas para el resumen\n",
    "        - Son las mismas: obtiener resumen de la tabla *ai_resumen_evolucion*  \n",
    "        - Son distintas: proceder al flujo del punto (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293fecb",
   "metadata": {},
   "source": [
    "## Flujo de trabajo\n",
    "\n",
    "Dado que los requerimientos son varios y requieren examen minucioso decidimos desagregar el proceso y crear un workflow de nodos con dedicación exclusiva a cada requerimiento.\n",
    "\n",
    "Workflow:\n",
    "1. Verificar si es necesario crear un nuevo resumen o mostrar el ultimo\n",
    "2. obtener datos relevantes de historia perinatal\n",
    "3. obtener datos relevantes de historia familiar\n",
    "4. obtener datos relevantes de metricas de crecimiento\n",
    "5. Cruzar datos de historia clinica con datos de historia perinatal\n",
    "6. Cruzar datos de histira clinica con los de historia familiar\n",
    "7. Analizar las curvas de crecimineto y cruzar esos datos con los datos de los antecedentes de enfermedades presentes en la historia clinica, los antecedentes perinatale o los antecedentes familiares\n",
    "8. Analisis de correlaciones entre los cruces de datos\n",
    "9. Redaccion de informe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa343c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6614ed",
   "metadata": {},
   "source": [
    "### Creando el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaciones\n",
    "%pip install langchain langchain-openai langchain_experimental python-dotenv matplotlib numpy pandas langgraph langchain-community langchain_tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689cdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2f3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurar el parser de salida\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Paciente(BaseModel):\n",
    "    id_paciente: int = Field(...)\n",
    "    apellido: str = Field(...)\n",
    "    nombre: str = Field(...)\n",
    "    fecha_nac: str = Field(...)\n",
    "    sexo: str = Field(...)\n",
    "    edad: str = Field(...)\n",
    "    dni: str = Field(...)\n",
    "    localidad: str = Field(...)\n",
    "    obra_social: str = Field(...)\n",
    "    afiliado_nro: str = Field(...)\n",
    "    telefono: str = Field(...)\n",
    "    telefono_numero: str = Field(...)\n",
    "    email: str = Field(...)\n",
    "    especialidad: str = Field(...)\n",
    "    diagnostico: str = Field(...)\n",
    "    enfermedad_base: str = Field(...)\n",
    "    ant_perinatales: str = Field(...)\n",
    "    ant_familiares: str = Field(...)\n",
    "    registro: str = Field(...)\n",
    "    fecha_registro: str = Field(...)\n",
    "    \n",
    "class Evolucion(BaseModel):\n",
    "    id: int = Field(...)\n",
    "    id_paciente: int = Field(...)\n",
    "    fecha: str = Field(...)\n",
    "    edad: int = Field(...)\n",
    "    uni_edad: Optional[str] = Field(None)\n",
    "    edad_anios: float = Field(...)\n",
    "    edad_texto: str = Field(...)\n",
    "    peso: float = Field(...)\n",
    "    talla: float = Field(...)\n",
    "    imc: float = Field(...)\n",
    "    pc: float = Field(...)\n",
    "    motivo: str = Field(...)\n",
    "    conducta: Optional[str] = Field(None)\n",
    "    \n",
    "class Resumen(BaseModel):\n",
    "    id_resume: int = Field(..., description=\"Identificador del resumen generado por la IA\")\n",
    "    id_paciente: int = Field(..., description=\"Identificador del paciente\")\n",
    "    resumen: str = Field(..., description=\"Resumen generado por IA\")\n",
    "    created_at: str = Field(..., description=\"Fecha de creación del resumen\")\n",
    "    updated_at: str = Field(..., description=\"Fecha de última actualización del resumen\")\n",
    "\n",
    "class ReferenciaEvolucion(BaseModel):\n",
    "    id: int = Field(..., description=\"Identificador de la respuesta generada por la IA\")\n",
    "    id_evolucion: int = Field(..., description=\"Identificador de la evolución\")\n",
    "    id_resume: int = Field(..., description=\"Identificador del resumen generado por la IA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6353c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccion de modelo\n",
    "llm = init_chat_model(\"openai:gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695dddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nodo para verificar si el paciente tiene resumen o no\n",
    "def ejecutar_query_sql(state: int) -> Paciente:\n",
    "    def query_to_database(query, db):\n",
    "        # 1. Connect to the SQLite database\n",
    "        conn = sqlite3.connect(db)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            # print(df)\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "            return df\n",
    "    \n",
    "    sql_query_paciente = f\"\"\"\n",
    "    SELECT * FROM paciente WHERE id_paciente = {id_paciente};\n",
    "    \"\"\"\n",
    "    paciente_df = query_to_database(sql_query_paciente, '../01_setup/data/consultorio.db')\n",
    "    if paciente_df.empty:\n",
    "        return None\n",
    "    paciente_dict = paciente_df.iloc[0].to_dict()\n",
    "    paciente = Paciente(**paciente_dict)\n",
    "    \n",
    "    return paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nodo que \n",
    "if paciente is None:\n",
    "    print(f\"No se encontró el paciente con ID {id_paciente}.\")\n",
    "    # Aquí puedes manejar el caso cuando no se encuentra el paciente\n",
    "else:\n",
    "    print(f\"Paciente encontrado: {paciente.nombre} {paciente.apellido}\")\n",
    "    # Aquí puedes continuar con el procesamiento del paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def obtener_ai_resumen_para_paciente(state: Paciente) -> str:\n",
    "   def query_to_database(query, db):\n",
    "    # 1. Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        # print(df)\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        return df\n",
    "\n",
    "# Obtener evolucion de un paciente\n",
    "id_paciente = 172\n",
    "sql_query_evolucion = f\"\"\"\n",
    "SELECT * FROM evolucion WHERE id_paciente = {id_paciente};\n",
    "\"\"\"\n",
    "evolucion_df = query_to_database(sql_query_evolucion, '../01_setup/data/consultorio.db')\n",
    "\n",
    "# Obtener datos personales del paciente\n",
    "sql_query_paciente = f\"\"\"\n",
    "SELECT * FROM paciente WHERE id_paciente = {id_paciente};\n",
    "\"\"\"\n",
    "\n",
    "    return { \"refined_query\": response.content.strip() }\n",
    "\n",
    "def search_trending_topics(state: TypedDictState) -> TypedDictState:\n",
    "    refined_query = state['refined_query']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the refined user query, your job is to search for trending topics related to it.\n",
    "\n",
    "    Refined query: {refined_query}\n",
    "\n",
    "    Trending topics:\"\"\"\n",
    "\n",
    "    response = llm.bind_tools([tavily_search]).invoke(prompt)\n",
    "\n",
    "    return { \"trending_topics\": response.content.strip() }\n",
    "\n",
    "def analyze_sentiment(state: TypedDictState) -> TypedDictState:\n",
    "\n",
    "    trending_topics = state['trending_topics']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the trending topics, your job is to analyze their sentiment.\n",
    "\n",
    "    Trending topics: {trending_topics}\n",
    "\n",
    "    Sentiment analysis:\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return { \"sentiment_analysis\": response.content.strip() }\n",
    "\n",
    "builder = StateGraph(TypedDictState)\n",
    "\n",
    "builder.add_node(\"refine_user_query\", refine_user_query)\n",
    "builder.add_node(\"search_trending_topics\", search_trending_topics)\n",
    "builder.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "\n",
    "builder.add_edge(START, \"refine_user_query\")\n",
    "builder.add_edge(\"refine_user_query\", \"search_trending_topics\")\n",
    "builder.add_edge(\"search_trending_topics\", \"analyze_sentiment\")\n",
    "builder.add_edge(\"analyze_sentiment\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
